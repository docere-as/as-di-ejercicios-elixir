# Gestor de recursos

En este ejercicio implementaremos un sencillo gestor de recursos
distribuido y resiliente en tres iteraciones.


## Objetivos de aprendizaje

  - Conocer las diferencias entre `pid()` y _nombres de procesos_ y
    su uso.
  
  - Comprender el dise帽o de m谩quinas distribuidas en elixir.
  
  - Conocer los mecanismos de distribuci贸n en elixir.
  
  - Conocer los mecanismos de tolerancia a fallos basados en procesos.
  
  - Comprender el mecanismo de _heartbeat_ de BEAM.
  

---


## El Modelo de Negocio (Reglas del Sistema)

El sistema gestiona una lista de **recursos** (representados
simplemente como **谩tomos**, ej: `:resource_1`, `:resource_2`).

**Reglas de Oro:**

1. **Exclusividad:** Un recurso concedido no puede darse a otro
   cliente hasta que sea liberado.

2. **Identidad:** Los clientes se identifican por su `pid()`.

3. **Flexibilidad:** Un cliente puede pedir y mantener varios recursos
   a la vez.

4. **Seguridad:** Un cliente no puede liberar un recurso que no ha
   reservado previamente.

---


## Hoja de Ruta: Las Tres Iteraciones

Para construir un sistema s贸lido, trabajaremos de forma incremental:

### Iteraci贸n 1: El N煤cleo (Local)

* **Escenario:** Todo ocurre en el mismo nodo (la misma m谩quina
  virtual de Elixir).

* **Objetivo:** Implementar la l贸gica l贸gica de asignaci贸n, b煤squeda y
  liberaci贸n.

* **Fichero:** `gestor-it1.ex`.

* **Importante:** El proceso servidor se registra con el nombre
  `gestor`.
  

### Iteraci贸n 2: Cruzando Fronteras (Distribuido)

* **Escenario:** El Gestor vive en un nodo y los Clientes en otros
  nodos distintos.

* **Objetivo:** Configurar el Gestor para que registre su nombre de
  forma **global** en la red de nodos. Los clientes deben poder
  encontrar al gestor sin conocer su PID exacto.

* **Fichero:** `gestor-it2.ex`.


### Iteraci贸n 3: El "Plan de Supervivencia" (Tolerancia a Fallos)

* **Escenario:** 驴Qu茅 pasa si un cliente pide un recurso y explota o
  su ordenador explota, o se apaga antes de devolverlo?

* **Objetivo:** El sistema debe detectar si un cliente muere o si su
  nodo se desconecta. En ese caso, el Gestor debe recuperar
  autom谩ticamente los recursos que ese cliente ten铆a "secuestrados" y
  volver a ponerlos disponibles.

* **Importante:** Deb茅is aprovechar los mecanismos nativos de la BEAM
  (monitores/enlaces). **No** reinvent茅is la rueda creando vuestro
  propio sistema de *heartbeat*.

* **Fichero:** `gestor-it3.ex`.

![](gestor-recursos-tolerancia-a-fallos.png)


---


## Especificaci贸n T茅cnica (API y Mensajer铆a)

Para facilitar la vida al usuario, el m贸dulo `Gestor` debe ocultar el
intercambio de mensajes tras una **API limpia**.

### Funciones del M贸dulo `Gestor`

| Funci贸n | Descripci贸n |
| --- | --- |
| `start(lista_recursos)` | Arranca el proceso, lo registra como `gestor` e inicializa los recursos (ej. `[:a, :b, :c]`). |
| `alloc()` | Solicita un recurso. Devuelve `{:ok, res}` o `{:error, :sin_recursos}`. |
| `release(res)` | Libera el recurso `res`. Devuelve `:ok` o `{:error, :recurso_no_reservado}`. |
| `avail()` | Devuelve el n煤mero (entero) de recursos libres en ese momento. |


### Protocolo de Mensajes Internos

La estructura interna de los mensajes debe ser:

| Petici贸n | Respuesta |
|`{:alloc, from}` | `{:ok, res}` o `{:error, :sin_recursos}` |
|`{:release, from, res}` | `:ok` o `{:error, :recurso_no_reservado}` |
|`{:avail, from}` | El n煤mero de recursos |

---

## Requisitos de Entrega y Calidad

1. **Sin Mix.** 

2. **Documentaci贸n:** El `README.md` debe incluir una gu铆a paso a paso
   de **c贸mo probar manualmente** cada iteraci贸n.

3. **Limpia y Ordenada:** Mantened las tres iteraciones en tres ficheros separados.


---


## И Gu铆a de Pruebas Manuales (Testing)

Aqu铆 ten茅is varios ejemplos del tipo de pruebas manuales que pod茅is
realizar para validar vuestro c贸digo.

###  Iteraci贸n 1: Entorno Local (Un solo nodo)

En esta fase, probamos que la l贸gica de asignaci贸n y liberaci贸n
funciona correctamente en un mismo entorno.

1. **Arrancar el Gestor:** `Gestor.start([:r1, :r2])`

2. **Verificar disponibilidad:** `Gestor.avail()` (Debe devolver `2`)

3. **Reservar recursos:** `Gestor.alloc()` (Debe devolver `{:ok, :r1}` o `{:ok, :r2}`)

4. **Intentar reservar sin stock:** `Gestor.alloc()`, `Gestor.alloc()` (Debe devolver `{:error, :sin_recursos}`)

5. **Liberar y re-asignar:** `Gestor.release(res1)` (Debe devolver
   `:ok`), a continuaci贸n `Gestor.avail()` (Debe devolver `1`)


Piensa c贸mo probar que un cliente no puede liberar un recurso que no
ha reservado.


###  Iteraci贸n 2: Entorno Distribuido

Aqu铆 comprobamos que el nombre global funciona y que los nodos se
comunican. Necesitar谩s al menos dos nodos de elixir. Prueba a abrir
**dos terminales** diferentes.

**Terminal A (Servidor):**

1. Inicia el nodo: `iex --sname servidor --cookie secreto gestor-it2.ex`
2. Arranca el gestor: `Gestor.start([:r1, :r2])`

**Terminal B (Cliente):**

1. Inicia el nodo: `iex --sname cliente --cookie secreto gestor-it2.ex`
2. Con茅ctate al servidor: `Node.connect(:"servidor@nombre_de_tu_host")`
3. **Ejecuta la API:** `Gestor.alloc()`

> **Nota:** Observa que no has tenido que pasarle el
> PID ni el nodo al llamar a `alloc()`. El sistema lo encuentra
> gracias al registro global.

A partir de aqu铆 has creado la m谩quina distribuida y puedes comenzar
las pruebas.


###  Iteraci贸n 3: Tolerancia a Fallos

El objetivo es ver c贸mo el gestor "limpia" el desorden que deja un
cliente cuando desaparece inesperadamente.

1. **Configuraci贸n:** Sigue los pasos de la **Iteraci贸n 2** (Servidor y Cliente conectados).

2. **Desde el Cliente:** Reserva un recurso: `{:ok, res} = Gestor.alloc()`.

3. **Desde el Servidor:** Comprueba que el recurso est谩 ocupado: `Gestor.avail()` (deber铆a quedar 1 libre si hab铆a 2).

4. **Simular el Fallo:**

  - **Opci贸n A (Fallo de proceso):** En la terminal del Cliente,
    averigua su PID y "m谩talo" desde usando `Process.exit(pid_cliente,
    :kill)`.
  
  - **Opci贸n B (Fallo de nodo):** Cierra repentinamente la terminal
    del Cliente o para la m谩quina virtual del nodo con `:erlang:halt()`.

5. **Verificar Recuperaci贸n (En el Servidor):**
  - **Opci贸n B:** Espera unos segundos (tiempo de detecci贸n del _heartbeat_).
  
  - * Ejecuta `Gestor.avail()`. **隆Magia!** El n煤mero de recursos
    disponibles debe haber aumentado autom谩ticamente, indicando que el
    gestor detect贸 la ca铆da y liber贸 el recurso `:r1`.


---


## Laboratorio de Reflexi贸n

Tras completar el c贸digo, preparaos para debatir estas cuestiones:

  - Si se apaga un nodo cliente por completo, 驴vuestro sistema
    recupera el recurso?

  - Si hay un corte de red temporal _split-brain_, 驴c贸mo reacciona el
    gestor cuando la red vuelve? 驴El sistema cree que el cliente ha
    muerto? 驴El sistema se puede quedar en un estado inconsistente?
    驴Existe alguna soluci贸n viable?

